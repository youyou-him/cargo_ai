{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66710712-430a-4f4c-a97d-3fc101068ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "      ë‹¨ê³„ 1: ì˜¤í”„ë¼ì¸ ëª¨ë¸ í•™ìŠµ (pkl íŒŒì¼ ìƒì„±)\n",
      "============================================================\n",
      "\n",
      "--- [ì˜¤í”„ë¼ì¸ í•™ìŠµ] 1ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ìƒì„± ì‹œì‘ ---\n",
      "-> 819ê±´ì˜ ì„±ê³µ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ì¬êµ¬ì„± ì¤‘...\n",
      "=> í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ! ì´ 1296630ê°œ í–‰ ìƒì„±.\n",
      "\n",
      "--- [ì˜¤í”„ë¼ì¸ í•™ìŠµ] 2ë‹¨ê³„: ML ë­í‚¹ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì‹œì‘ ---\n",
      "-> ì „ì²´ 819ê°œ ë¬¸ì œ ì¤‘ 655ê°œëŠ” í•™ìŠµìš©, 164ê°œëŠ” ê²€ì¦ìš©ìœ¼ë¡œ ë¶„ë¦¬.\n",
      "\n",
      "-> ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ (ê²€ì¦ìš© ë°ì´í„°ë¡œ nDCG ì ìˆ˜ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 662\n",
      "[LightGBM] [Info] Number of data points in the train set: 1037332, number of used features: 3\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's ndcg@5: 0.786703\n",
      "\n",
      "--- í•™ìŠµ ì™„ë£Œ ---\n",
      "âœ… ìµœì¢… ê²€ì¦ nDCG@5 ì ìˆ˜: 0.7867\n",
      "=> ìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸ì„ 'lgbm_ranker_model.pkl' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "-> í•™ìŠµ ê³¼ì •ì— ë”°ë¥¸ nDCG ì ìˆ˜ ë³€í™”ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 234\u001b[0m\n\u001b[0;32m    232\u001b[0m training_df \u001b[38;5;241m=\u001b[39m create_training_data(cargo_data, driver_full_data, simulation_results)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m training_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlgbm_ranker_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì˜¤ë¥˜: í•™ìŠµ ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 152\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[1;34m(df_train, model_path)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# â˜…â˜…â˜… ì£¼ìš” ìˆ˜ì • ì‚¬í•­: ì‹œê°í™” ì½”ë“œë¥¼ í•¨ìˆ˜ ì•ˆìœ¼ë¡œ í†µí•©í–ˆìŠµë‹ˆë‹¤. â˜…â˜…â˜…\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-> í•™ìŠµ ê³¼ì •ì— ë”°ë¥¸ nDCG ì ìˆ˜ ë³€í™”ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m    153\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(ranker\u001b[38;5;241m.\u001b[39mevals_result_[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndcg@5\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation nDCG@5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    154\u001b[0m plt\u001b[38;5;241m.\u001b[39maxvline(x\u001b[38;5;241m=\u001b[39mranker\u001b[38;5;241m.\u001b[39mbest_iteration_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Iteration (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mranker\u001b[38;5;241m.\u001b[39mbest_iteration_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. ìƒìˆ˜ ë° í—¬í¼ í•¨ìˆ˜ ì •ì˜\n",
    "# ==============================================================================\n",
    "\n",
    "AVERAGE_TRUCK_SPEED_KPH = 50\n",
    "CITY_COORDS = {\n",
    "    'ì„œìš¸': (37.566, 126.978), 'ë¶€ì‚°': (35.180, 129.075), 'ëŒ€êµ¬': (35.871, 128.601),\n",
    "    'ì¸ì²œ': (37.456, 126.705), 'ê´‘ì£¼': (35.160, 126.851), 'ëŒ€ì „': (36.350, 127.384),\n",
    "    'ìš¸ì‚°': (35.538, 129.311), 'ìˆ˜ì›': (37.263, 127.028), 'ì°½ì›': (35.228, 128.681),\n",
    "    'ì²­ì£¼': (36.642, 127.489)\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    dLat, dLon = radians(lat2 - lat1), radians(lon2 - lon1)\n",
    "    a = sin(dLat / 2) ** 2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dLon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def estimate_time_from_distance(distance_km):\n",
    "    return timedelta(hours=distance_km / AVERAGE_TRUCK_SPEED_KPH)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# A. ì˜¤í”„ë¼ì¸ í•™ìŠµ ë¶€ë¶„\n",
    "# ==============================================================================\n",
    "\n",
    "def create_training_data(cargo_df, driver_df, results_df):\n",
    "    print(\"\\n--- [ì˜¤í”„ë¼ì¸ í•™ìŠµ] 1ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ìƒì„± ì‹œì‘ ---\")\n",
    "    training_data_rows = []\n",
    "    successful_matches = results_df[results_df['status'] == 'Matched'].copy()\n",
    "    print(f\"-> {len(successful_matches)}ê±´ì˜ ì„±ê³µ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ì¬êµ¬ì„± ì¤‘...\")\n",
    "\n",
    "    all_drivers = driver_df.copy()\n",
    "    all_drivers['acceptance_rate'] = (all_drivers['accepted_requests'] / all_drivers['total_requests']).fillna(0)\n",
    "\n",
    "    for index, log_row in successful_matches.iterrows():\n",
    "        query_id = f\"{index}_{log_row['request_id']}\"\n",
    "        actual_matched_driver = log_row['matched_driver']\n",
    "\n",
    "        current_cargo_series = cargo_df[cargo_df['shipper_id'] == log_row['request_id']]\n",
    "        if current_cargo_series.empty: continue\n",
    "        current_cargo = current_cargo_series.iloc[0]\n",
    "\n",
    "        # ê¸°ë³¸ ìê²© í•„í„°ë§\n",
    "        candidate_drivers = all_drivers[all_drivers['max_load_kg'] >= float(current_cargo['weight_kg'])].copy()\n",
    "        cargo_type = current_cargo['cargo_type']\n",
    "        if cargo_type == 'ëƒ‰ì¥':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == 'ëƒ‰ì¥']\n",
    "        elif cargo_type == 'ëƒ‰ë™':\n",
    "            candidate_drivers = candidate_drivers[candidate_drivers['vehicle_type'] == 'ëƒ‰ë™']\n",
    "        # ... (ë‹¤ë¥¸ í™”ë¬¼ ìœ í˜• í•„í„°ë§ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)\n",
    "        if candidate_drivers.empty: continue\n",
    "\n",
    "        # ê±°ë¦¬ ê¸°ë°˜ í›„ë³´êµ° ì¶•ì†Œ\n",
    "        pickup_lat, pickup_lon = CITY_COORDS[current_cargo['origin']]\n",
    "        lat_diff_limit, lon_diff_limit = 2.0, 2.0  # 200km ë°˜ê²½\n",
    "        realistic_candidates = candidate_drivers[\n",
    "            (abs(candidate_drivers['latitude'] - pickup_lat) < lat_diff_limit) &\n",
    "            (abs(candidate_drivers['longitude'] - pickup_lon) < lon_diff_limit)\n",
    "            ].copy()\n",
    "\n",
    "        # ì‹¤ì œ ë§¤ì¹­ëœ ê¸°ì‚¬ê°€ í›„ë³´êµ°ì— í¬í•¨ë˜ë„ë¡ ë³´ì¥\n",
    "        if actual_matched_driver not in realistic_candidates['driver_id'].values:\n",
    "            matched_driver_info = all_drivers[all_drivers['driver_id'] == actual_matched_driver]\n",
    "            realistic_candidates = pd.concat([realistic_candidates, matched_driver_info], ignore_index=True)\n",
    "\n",
    "        # íŠ¹ì§•(Feature) ë° ì •ë‹µ(Relevance) ìƒì„±\n",
    "        realistic_candidates['distance'] = realistic_candidates.apply(\n",
    "            lambda r: calculate_distance(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1\n",
    "        )\n",
    "        realistic_candidates['relevance'] = np.where(realistic_candidates['driver_id'] == actual_matched_driver, 2, 1)\n",
    "\n",
    "        for _, driver_row in realistic_candidates.iterrows():\n",
    "            training_data_rows.append({\n",
    "                'query_id': query_id,\n",
    "                'distance': driver_row['distance'],\n",
    "                'rating': driver_row['rating'],\n",
    "                'acceptance_rate': driver_row['acceptance_rate'],\n",
    "                'relevance': driver_row['relevance']\n",
    "            })\n",
    "\n",
    "    final_df = pd.DataFrame(training_data_rows)\n",
    "    print(f\"=> í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ! ì´ {len(final_df)}ê°œ í–‰ ìƒì„±.\")\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def train_and_save_model(df_train, model_path='lgbm_ranker_model.pkl'):\n",
    "    print(\"\\n--- [ì˜¤í”„ë¼ì¸ í•™ìŠµ] 2ë‹¨ê³„: ML ë­í‚¹ ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì‹œì‘ ---\")\n",
    "    \n",
    "    # --- ë°ì´í„° ë¶„ë¦¬ (í•™ìŠµìš© / ê²€ì¦ìš©) ---\n",
    "    all_query_ids = df_train['query_id'].unique()\n",
    "    train_qids, val_qids = train_test_split(all_query_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_df = df_train[df_train['query_id'].isin(train_qids)]\n",
    "    val_df = df_train[df_train['query_id'].isin(val_qids)]\n",
    "    \n",
    "    print(f\"-> ì „ì²´ {len(all_query_ids)}ê°œ ë¬¸ì œ ì¤‘ {len(train_qids)}ê°œëŠ” í•™ìŠµìš©, {len(val_qids)}ê°œëŠ” ê²€ì¦ìš©ìœ¼ë¡œ ë¶„ë¦¬.\")\n",
    "\n",
    "    # í•™ìŠµìš© ë° ê²€ì¦ìš© ë°ì´í„° ì¤€ë¹„\n",
    "    features = ['distance', 'rating', 'acceptance_rate']\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['relevance']\n",
    "    group_train = train_df.groupby('query_id').size().to_list()\n",
    "\n",
    "    X_val = val_df[features]\n",
    "    y_val = val_df['relevance']\n",
    "    group_val = val_df.groupby('query_id').size().to_list()\n",
    "\n",
    "    # --- ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ---\n",
    "    ranker = lgb.LGBMRanker(\n",
    "        objective=\"lambdarank\",\n",
    "        metric=\"ndcg\",\n",
    "        random_state=42,\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05\n",
    "    )\n",
    "    \n",
    "    print(\"\\n-> ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤ (ê²€ì¦ìš© ë°ì´í„°ë¡œ nDCG ì ìˆ˜ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤)...\")\n",
    "    \n",
    "    ranker.fit(\n",
    "        X=X_train, \n",
    "        y=y_train, \n",
    "        group=group_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_group=[group_val],\n",
    "        eval_at=[5],\n",
    "        callbacks=[lgb.early_stopping(10, verbose=True)]\n",
    "    )\n",
    "\n",
    "    # --- ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ ---\n",
    "    best_score = ranker.best_score_['valid_0']['ndcg@5']\n",
    "    print(f\"\\n--- í•™ìŠµ ì™„ë£Œ ---\")\n",
    "    print(f\"âœ… ìµœì¢… ê²€ì¦ nDCG@5 ì ìˆ˜: {best_score:.4f}\")\n",
    "    \n",
    "    joblib.dump(ranker, model_path)\n",
    "    print(f\"=> ìµœê³  ì„±ëŠ¥ì˜ ëª¨ë¸ì„ '{model_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    # â˜…â˜…â˜… ì£¼ìš” ìˆ˜ì • ì‚¬í•­: ì‹œê°í™” ì½”ë“œë¥¼ í•¨ìˆ˜ ì•ˆìœ¼ë¡œ í†µí•©í–ˆìŠµë‹ˆë‹¤. â˜…â˜…â˜…\n",
    "    print(\"\\n-> í•™ìŠµ ê³¼ì •ì— ë”°ë¥¸ nDCG ì ìˆ˜ ë³€í™”ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ranker.evals_result_['valid_0']['ndcg@5'], label='Validation nDCG@5')\n",
    "    plt.axvline(x=ranker.best_iteration_ - 1, color='r', linestyle='--', label=f'Best Iteration ({ranker.best_iteration_})')\n",
    "    plt.title('nDCG Score over Training Iterations')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('nDCG@5 Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# B. ì˜¨ë¼ì¸ ì˜ˆì¸¡ ë¶€ë¶„\n",
    "# ==============================================================================\n",
    "\n",
    "class RealtimeMatcher:\n",
    "    def __init__(self, model_path, driver_db_path, driver_loc_path):\n",
    "        print(\"\\n--- [ì˜¨ë¼ì¸ ì˜ˆì¸¡] ì´ˆê¸°í™”: RealtimeMatcher ë¡œë“œ ì‹œì‘ ---\")\n",
    "        self.ranker = joblib.load(model_path)\n",
    "\n",
    "        driver_harmful_df = pd.read_csv(driver_db_path)\n",
    "        driver_loc_df = pd.read_csv(driver_loc_path)\n",
    "        self.driver_database = pd.merge(driver_harmful_df, driver_loc_df, on='driver_id', how='left')\n",
    "        self.driver_database['acceptance_rate'] = (\n",
    "                    self.driver_database['accepted_requests'] / self.driver_database['total_requests']).fillna(0)\n",
    "        self.driver_database['next_available_time_dt'] = pd.to_datetime(datetime.now())\n",
    "        print(\"-> ë“œë¼ì´ë²„ ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ë° ì´ˆê¸°í™” ì™„ë£Œ.\")\n",
    "\n",
    "    def recommend_top_drivers(self, new_cargo_request, top_n=5):\n",
    "        print(f\"\\n--- [ì˜¨ë¼ì¸ ì˜ˆì¸¡] ìš”ì²­ ì²˜ë¦¬ ì‹œì‘: {new_cargo_request['origin']} -> {new_cargo_request['destination']} ---\")\n",
    "        request_time_dt = datetime.strptime(new_cargo_request['request_time'], '%Y-%m-%d %H:%M:%S')\n",
    "        deadline_dt = datetime.strptime(new_cargo_request['deadline'], '%Y-%m-%d %H:%M:%S')\n",
    "        pickup_lat, pickup_lon = CITY_COORDS[new_cargo_request['origin']]\n",
    "        delivery_lat, delivery_lon = CITY_COORDS[new_cargo_request['destination']]\n",
    "\n",
    "        # 1. ìê²©/ê±°ë¦¬/ì‹œê°„ í•„í„°ë§\n",
    "        candidates = self.driver_database.copy()\n",
    "        candidates = candidates[ã„´ã„´\n",
    "            (candidates['max_load_kg'] >= new_cargo_request['weight_kg']) &\n",
    "            (candidates['next_available_time_dt'] < deadline_dt)  # ìµœì†Œí•œì˜ ì‹œê°„ ì¡°ê±´\n",
    "            ]\n",
    "        candidates['distance'] = candidates.apply(\n",
    "            lambda r: calculate_distance(r['latitude'], r['longitude'], pickup_lat, pickup_lon), axis=1)\n",
    "        candidates = candidates[candidates['distance'] < 200].copy()  # 200km ì´ë‚´\n",
    "\n",
    "        if candidates.empty:\n",
    "            print(\"-> ì¡°ê±´ì— ë§ëŠ” í›„ë³´ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "\n",
    "        print(f\"-> í•„í„°ë§ í›„ ìµœì¢… {len(candidates)}ëª…ì˜ í›„ë³´ë¡œ ì••ì¶•.\")\n",
    "\n",
    "        # 2. ëª¨ë¸ ì˜ˆì¸¡\n",
    "        features = ['distance', 'rating', 'acceptance_rate']\n",
    "        X_predict = candidates[features]\n",
    "        candidates['predicted_score'] = self.ranker.predict(X_predict)\n",
    "\n",
    "        # 3. ìµœì¢… ê²°ê³¼ ë°˜í™˜\n",
    "        final_recommendations = candidates.sort_values('predicted_score', ascending=False)\n",
    "        print(\"--- [ì˜¨ë¼ì¸ ì˜ˆì¸¡] ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ ---\")\n",
    "        return final_recommendations.head(top_n)\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# C. ì „ì²´ ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ ë¡œì§\n",
    "# ==============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # --- C-1. ì˜¤í”„ë¼ì¸ í•™ìŠµ ë‹¨ê³„ ì‹¤í–‰ ---\n",
    "    print(\"=\" * 60)\n",
    "    print(\"      ë‹¨ê³„ 1: ì˜¤í”„ë¼ì¸ ëª¨ë¸ í•™ìŠµ (pkl íŒŒì¼ ìƒì„±)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ë°ì´í„° ë¡œë“œ\n",
    "    cargo_data = pd.read_csv('cargo.csv')\n",
    "    driver_harmful_data = pd.read_csv('driver_harmful.csv')\n",
    "    driver_loc_data = pd.read_csv('driver_loc.csv')\n",
    "    simulation_results = pd.read_csv('simulation_results_generated.csv')\n",
    "\n",
    "    driver_full_data = pd.merge(driver_harmful_data, driver_loc_data, on='driver_id')\n",
    "\n",
    "    # í•™ìŠµ ë°ì´í„° ìƒì„± ë° ëª¨ë¸ í•™ìŠµ/ì €ì¥\n",
    "    training_df = create_training_data(cargo_data, driver_full_data, simulation_results)\n",
    "    if not training_df.empty:\n",
    "        train_and_save_model(training_df, model_path='lgbm_ranker_model.pkl')\n",
    "    else:\n",
    "        print(\"ì˜¤ë¥˜: í•™ìŠµ ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    # --- C-2. ì˜¨ë¼ì¸ ì˜ˆì¸¡ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"      ë‹¨ê³„ 2: ì˜¨ë¼ì¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    matcher = RealtimeMatcher(\n",
    "        model_path='lgbm_ranker_model.pkl',\n",
    "        driver_db_path='driver_harmful.csv',\n",
    "        driver_loc_path='driver_loc.csv'\n",
    "    )\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ìš© ì‹ ê·œ í™”ë¬¼ ìš”ì²­\n",
    "    test_cargo_request = {\n",
    "        'origin': 'ì„œìš¸', 'destination': 'ë¶€ì‚°', 'weight_kg': 2000,\n",
    "        'cargo_type': 'ì¼ë°˜', 'request_time': '2025-07-15 18:00:00',\n",
    "        'deadline': '2025-07-16 12:00:00'\n",
    "    }\n",
    "\n",
    "    # ì¶”ì²œ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ë°›ê¸°\n",
    "    top_drivers = matcher.recommend_top_drivers(test_cargo_request, top_n=5)\n",
    "\n",
    "    if top_drivers is not None:\n",
    "        print(\"\\n---  ìµœì¢… ì¶”ì²œ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ (ìƒìœ„ 5ëª…) ---\")\n",
    "        print(\"=> AI ëª¨ë¸ì´ ì˜ˆì¸¡í•œ, ì´ í™”ë¬¼ì„ ê°€ì¥ ì˜ ì²˜ë¦¬í•  ê²ƒ ê°™ì€ ê¸°ì‚¬ ìˆœìœ„ì…ë‹ˆë‹¤.\")\n",
    "        print(top_drivers[['driver_id', 'predicted_score', 'distance', 'rating', 'vehicle_type']])\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"      ğŸ‰ ëª¨ë“  ê³¼ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c0b3ca-2c41-4587-a66d-3ca316648b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRanker(learning_rate=0.05, metric='ndcg', n_estimators=200,\n",
      "           objective='lambdarank', random_state=42)\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load('model/lgbm_ranker_model.pkl')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722b4a8-8f10-406f-8456-e7c382005e73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd8acc-92a4-49db-955c-5d5ea069f769",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
